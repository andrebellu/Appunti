%!TeX root = subfile
\documentclass[../main.tex]{subfiles}
\begin{document}

\section{Forme Bilineari e Prodotti Scalari}

% pagine 85 86 87 finisci

\subsection{Forme Bilineari}
Sia $\V$ uno spazio vettoriale sul campo $\mathbb{K}$. Una \textbf{forma
    bilineare} su $\mathbb{V}$ è un'applicazione
\[
    *: \V \times \V \rightarrow \mathbb{K}
\]
tale che $\forall \textbf{v,u,w} \in \mathbb{V} \text{ e } k\in\mathbb{K}$
\begin{enumerate}
    \item $ (\textbf{v}+\textbf{u})* \textbf{w} = (\textbf{v}*\textbf{w})+ (\textbf{u}*\textbf{w})$
    \item $\textbf{v}*(\textbf{u}+\textbf{w}) = (\textbf{v}*\textbf{u})+ (\textbf{v}*\textbf{w})$
    \item $ (k\textbf{v})*\textbf{u}=\textbf{v}* (k\textbf{u})=k (\textbf{v}*\textbf{u})$
\end{enumerate}
Si deduce che $0*\textbf{v} = \textbf{v}*0 = 0, \forall\ \textbf{v}\in\mathbb{V}$.

\subsection{Forma bilineare simmetrica}
Una forma bilineare $*$, su uno spazio vettoriale $\V$, si dice \textbf{forma
    bilineare simmetrica o prodotto scalare} se, comunque si considerino due
vettori $\textbf{v}$ e $\textbf{w}$ in $\V$, si ha:
\[
    \textbf{v}*\textbf{w} = \textbf{w} * \textbf{v}\]

\subsection{Prodotti scalari e ortogonalità}
In uno spazio vettoriale $\V$, con prodotto scalare ''$\cdot$'', due vettori
$\textbf{v}$ e $\textbf{w}$ si dicono \textbf{ortogonali} e si scrive
$\textbf{v}\perp\textbf{w}$ se $\textbf{v}\cdot\textbf{w} = 0$.

\subsection{Complemento ortogonale}
Sia $\V$ uno spazio vettoriale con prodotto scalare ''$\cdot$'' e sia $A$ un
sottoinsieme, non vuoto, di $\mathbb{V}$. Si dice \textbf{complemento
    ortogonale} di $A$ in $\Vx{n}$, l'insieme (si legge $A$ ortogonale)
\[
    A^{\perp} = \textbf{v}\in \mathbb{V}\ |\ \textbf{v}\cdot \textbf{w} = 0,\forall\textbf{w}\in A
\]

\subsubsection{Proposizione}
Sia $\V$ uno spazio vettoriale con prodotto scalare ''$\cdot$'' e sia
$\textbf{w}$ un vettore di $\V$ tale che $\textbf{w}\cdot\textbf{w}\ne0$.
Allora, ogni vettore \textbf{v} di $\V$ si può esprimere come somma di due
vettori $\textbf{w}_1$ e $\textbf{w}_2$, dove $\textbf{w}_1$ è ortogonale a
$\textbf{w}$ e $\textbf{w}_2$ è proporzionale a $\textbf{w}$. \\
\textbf{Dimostrazione:} Ogni vettore $\textbf{v}\in\V$ si può scrivere come:
\[
    \textbf{v} = \left(\textbf{v}-\dfrac{\textbf{v}\cdot \textbf{w}}{\textbf{w}\cdot \textbf{w}}\right) + \left(\dfrac{\textbf{v}\cdot \textbf{w}}{\textbf{w}\cdot \textbf{w}}\textbf{w}\right)
\]
Un calcolo diretto dimostra che $\textbf{w}_1 =
    \textbf{v}-\dfrac{\textbf{v}\cdot \textbf{w}}{\textbf{w}\cdot
        \textbf{w}}\textbf{w}$ è ortogonale $\textbf{w}$ mentre, ovviamente,
$\textbf{w}_2 = \dfrac{\textbf{v}\cdot \textbf{w}}{\textbf{w}\cdot
        \textbf{w}}\textbf{w}$ è proporzionale a $\textbf{w}$, secondo lo scalare
$\dfrac{\textbf{v}\cdot \textbf{w}}{\textbf{w}\cdot \textbf{w}}$

\subsection{Coefficiente di Fourier}
Sia $\V$ uno spazio vettoriale con prodotto scalare ''$\cdot$'' e sia
$\textbf{w}$ un vettore di $\mathbb{V}$ tale che
$\textbf{w}\cdot\textbf{w}\ne0$. Se $\textbf{v}$ è un vettore di $\V$, si dice
\textbf{coefficiente} o \textbf{componente di Fourier} di $\textbf{v}$ lungo
$\textbf{w}$ il numero reale
\[
    \textbf{v}_w = \dfrac{\textbf{v}\cdot \textbf{w}}{\textbf{w}\cdot \textbf{w}}
\]
e si dice \textbf{proiezione} di $\textbf{v}$ su $\textbf{w}$ il vettore $
    \overrightarrow{\textbf{v}} = \textbf{v}_w\textbf{w}$.

\subsection{Forme Quadratiche}
Sia $\V$ uno spazio vettoriale con prodotto scalare ''$\cdot$''. Si dice
\textbf{forma quadratica}, associata al prodotto scalare ''$\cdot$'',
l'applicazione
\[
    q: \V \rightarrow \mathbb{K}
\]
\[
    \textbf{v}\rightarrow\textbf{v}\cdot\textbf{v}
\]

\subsection{Spazi con prodotto scalare definito positivo}
Un prodotto scalare, assegnato in uno spazio vettoriale $\V$ su un campo
ordinato, si dice \textbf{definito positivo} se
$\forall\textbf{v}\in\mathbb{V},\textbf{v}\cdot\textbf{v}\geq0$ e
$\textbf{v}\cdot\textbf{v}=0\iff\textbf{v}=\underbar{0}$

Una forma quadratica si dice \textbf{definita positiva} se tale è il prodotto
scalare cui essa è associata.

\subsection{Norma}
Dato un vettore $\textbf{v}\in\mathbb{V}^{\circ}(\mathbb{R})$ si dice
\textbf{norma} di $\textbf{v}$ il numero reale positivo o nullo
\[
    ||\textbf{v}|| = \sqrt{\textbf{v}\cdot\textbf{v}} = \sqrt{\textbf{v}^2} = \sqrt{q(\textbf{v})}
\]

\subsection{Versore}
Sia $\textbf{v}\ne0$ un vettore di $\mathbb{V}^{\circ} (\mathbb{R})$, si dice
\textbf{versore} di $\textbf{v}$ il vettore
\[
    \textbf{v}' = \dfrac{\textbf{v}}{||\textbf{v}||}
\]

\subsection{Disuguaglianza di Cauchy-Schwarz}
Siano \textbf{v} e \textbf{u} due vettori di $\mathbb{V}^{\circ} (\mathbb{R})$.
Allora
\[
    |\textbf{v}\cdot\textbf{u}|\leq||\textbf{v}||\cdot||\textbf{u}||
\]
ove $|v\cdot u|$ indica il valore assoluto di $\textbf{v}\cdot\textbf{u}$.

\subsubsection{Dimostrazione}
Siano non nulli i vettori $\textbf{v}$ e $\textbf{w}$. Diversamente la tesi è
immediata. Per ongi numero reale $\ah$ si ha
\[
    0\leq(\ah\textbf{u}+\textbf{v})^2= (\textbf{u}\cdot\textbf{u})\ah^2+2(\textbf{u}\cdot\textbf{v})\ah+(\textbf{v}\cdot\textbf{v})\]

e quindi, al variare di $\ah\in\mathbb{R}$, il trinomio
\[
    ||\textbf{u}||^2\ah^2+2(\textbf{u}\cdot\textbf{v})\ah+||\textbf{v}||^2
\]

è maggiore o al più uguale a zero. Il suo discriminante non può, pertanto, essere positivo perchè se lo fosse, al variare di $\ah$, il trinomio cambierebbe segno. Risulta
\[
    \dfrac{\Delta}{4} = |\textbf{u}\cdot\textbf{v}|^2 - ||\textbf{u}||^2||\textbf{v}||^2\leq0\]

\subsection{Disuguaglianza triangolare}
Siano \textbf{v} e \textbf{u} due vettori di $\mathbb{V}^{\circ} (\mathbb{R})$.
Allora
\[
    ||\textbf{v}+\textbf{u}||\leq||\textbf{v}||+||\textbf{u}||
\]

\subsubsection{Dimostrazione}
Sono immediati i seguenti calcoli:
\[
    ||\textbf{v}+\textbf{u}||^2=||\textbf{u}||^2+\textbf{u}\cdot\textbf{v}+\textbf{v}\cdot\textbf{u}+||\textbf{v}||^2\leq||\textbf{u}||^2+2|\textbf{u}\cdot\textbf{v}|+||\textbf{v}||^2
\]
Applicando la disuguaglianza di Cauchy-Schwarz si ottiene la tesi:
\[
    ||\textbf{v}+\textbf{u}||^2\leq||\textbf{u}||^2+2||\textbf{u}|| ||\textbf{v}||+||\textbf{v}^2||=(||\textbf{u}||+||\textbf{v}||)^2
\]

\subsection{Osservazione}:
I vettori della base canonica $B = (\s{e}{n})$, dello spazio euclideo reale $\mathbb{R}^n$, godono delle seguenti proprietà:
\begin{enumerate}
    \item hanno norma unitaria, cioè, $||e_i||=1 \text{ per } i=1,2\cdots n$;
    \item sono tra loro ortogonali, cioè, $e_i\cdot e_j = 0$ per $i\ne j$ ove $i, j\in
              I_n$
    \item la $i$-esima componente, di un qualunque vettore $(\s{x}{n})$ di
          $\mathbb{R}^n$, si ottiene moltiplicando scalarmente quel vettore per $e_i$.
\end{enumerate}
Diremo che i vettori $\s{v}{r}$, di uno spazio vettoriale
$\mathbb{V}^{\circ}(\mathbb{V})$, tutti diversi dal vettore nullo,
costituiscono un \textbf{sistema ortogonale} se $\textbf{v}_i\cdot\textbf{v}_j
    = 0$, per $i\ne j $ e $i,j\in I_r$. Se, inoltre, hanno norma unitario, essi
costituiscono un \textbf{sistema ortonormale}. Una base, che sia anche un
sistema ortogonale. Una base, che sia anche un sistema ortogonale, si dice
\textbf{base orotogonale} e, se i suoi vettori hanno norma unitaria tale base
si dice \textbf{base ortonormale}. Ovviamente il vettore nullo è ortogonale a
tutti i vettori di $\mathbb{V}$. Da un sistema (o da una base) ortogonale di
$\mathbb{V}$ si può sempre ricavare una base ortonormale di $\mathbb{V}$,
dividendo ciascun vettore del sistema per la sua norma.\\ \\ I vettori della
base canonica, di uno spazio euclideo reale, costituiscono una base
ortonormale, ma \textbf{possiamo dimostrare che, in ogni spazio vettoriale f.g.
    con prodotto scalare definito positivo, è possibile costruire una base
    ortonormale che possiede le stesse proprietà che la base canonica ha negli
    spazi euclidei}.

\subsubsection{Lemma}
In uno spazio vettoriale $\mathbb{V}^{\circ}(\mathbb{R})$, se i vettori non
nulli $\s{\textbf{v}}{r}$, costituiscono un sistema ortogonale, allora sono
linearmente indipendenti.\\ Partendo da una qualsiasi base di
$\mathbb{V}^{\circ}(\mathbb{R})$, possiamo ora costrure una base ortogonale
seguendo il procedimento detto \textbf{processo di ortogonalizzazione di
    Gram-Schmidt}.\\

\subsubsection{Teorema}
Fissata una base $B = (\s{e}{n})$ di $\mathbb{V}^{\circ}(\mathbb{R})$, la
sequenza $B' = (\s{e'}{n})$ così costruita
\[
    \textbf{e}_1' = \textbf{e}_1
\]
\[
    \textbf{e}_2' = \textbf{e}_2 - \dfrac{\textbf{e}_2\cdot\textbf{e}_1'}{\textbf{e}_1'\cdot\textbf{e}_1'}\textbf{e}_1'
\]
\[
    \cdots \ \ \ \ \ \ \cdots\cdots\cdots\cdots\cdots\cdots
\]
\[
    \textbf{e'}_n = \textbf{e}_n - \dfrac{\textbf{e}_n\cdot\textbf{e'}_{n-1}}{\textbf{e'}_{n-1}\cdot\textbf{e'}_{n-1}}\textbf{e'}_{n-1} - \cdots - \dfrac{\textbf{e}_n\cdot\textbf{e}_1'}{\textbf{e}_1'\cdot\textbf{e}_1'}\textbf{e}_1'
\]

E' evidente che, \textbf{volendo determinare una base ortonormale di uno spazio
    vettoriale con prodotto scalare definito positivo, basta normalizzare la base
    ottenuta applicando il processo di ortogonalizzazione di Gram-Schmidt a una
    base qualunque dello spazio.}

\subsection{Lemma}
Se i vettori non nulli $\s{\textbf{v}}{r}$, costituiscono un sistema ortogonale
di $\mathbb{V}^{\circ}(\mathbb{R})$, allora esiste una base ortogonale che li
contiene.

\end{document}